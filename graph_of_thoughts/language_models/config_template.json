{
    "chatgpt" : {
        "model_id": "gpt-3.5-turbo",
        "prompt_token_cost": 0.0015,
        "response_token_cost": 0.002,
        "temperature": 1.0,
        "max_tokens": 1536,
        "stop": null,
        "organization": "",
        "api_key": ""
    },
    "chatgpt4" : {
        "model_id": "gpt-4",
        "prompt_token_cost": 0.03,
        "response_token_cost": 0.06,
        "temperature": 1.0,
        "max_tokens": 4096,
        "stop": null,
        "organization": "",
        "api_key": ""
    },
    "llama7b-hf" : {
        "model_id": "Llama-2-7b-chat-hf",
        "cache_dir": "/llama",
        "prompt_token_cost": 0.0,
        "response_token_cost": 0.0,
        "temperature": 0.6,
        "top_k": 10,
        "max_tokens": 4096
    },
    "llama13b-hf" : {
        "model_id": "Llama-2-13b-chat-hf",
        "cache_dir": "/llama",
        "prompt_token_cost": 0.0,
        "response_token_cost": 0.0,
        "temperature": 0.6,
        "top_k": 10,
        "max_tokens": 4096
    },
    "llama70b-hf" : {
        "model_id": "Llama-2-70b-chat-hf",
        "cache_dir": "/llama",
        "prompt_token_cost": 0.0,
        "response_token_cost": 0.0,
        "temperature": 0.6,
        "top_k": 10,
        "max_tokens": 4096
    },
    "chatglm3-6b" : {
        "model_id": "chatglm3-6b",
        "cache_dir": "/chatglm3",
        "model_path": "/home/lc/projects/pretrained_models/chatglm3-6b",
        "device": "cuda:0",
        "prompt_token_cost": 0.0,
        "response_token_cost": 0.0,
        "temperature": 0.6,
        "top_k": 10,
        "max_tokens": 4096
    },
    "Baichuan2-13B-Chat" : {
        "model_id": "Baichuan2-13B-Chat",
        "cache_dir": "/baichuan2",
        "model_path": "/home/lc/projects/pretrained_models/Baichuan2-13B-Chat",
        "prompt_token_cost": 0.0,
        "response_token_cost": 0.0,
        "temperature": 0.6,
        "top_k": 10,
        "max_tokens": 4096
    }
}
